layer {
  name: "minusscalar0_second"
  type: "Input"
  top: "minusscalar0_second"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 112
      dim: 112
    }
  }
}
layer {
  name: "mulscalar0_second"
  type: "Input"
  top: "mulscalar0_second"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 112
      dim: 112
    }
  }
}
layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 112
      dim: 112
    }
  }
}
layer {
  name: "minusscalar0"
  type: "Eltwise"
  bottom: "data"
  bottom: "minusscalar0_second"
  top: "minusscalar0"
  eltwise_param {
    coeff: 1.0
    coeff: -1.0
  }
}
layer {
  name: "mulscalar0"
  type: "Eltwise"
  bottom: "minusscalar0"
  bottom: "mulscalar0_second"
  top: "mulscalar0"
  eltwise_param {
    operation: PROD
  }
}
layer {
  name: "conv_1_conv2d"
  type: "Convolution"
  bottom: "mulscalar0"
  top: "conv_1_conv2d"
  convolution_param {
    num_output: 64
    bias_term: false
    group: 1
    stride: 2
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "conv_1_batchnorm"
  type: "BatchNorm"
  bottom: "conv_1_conv2d"
  top: "conv_1_batchnorm"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000475
  }
}
layer {
  name: "conv_1_batchnorm_scale"
  type: "Scale"
  bottom: "conv_1_batchnorm"
  top: "conv_1_batchnorm"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv_1_relu"
  type: "PReLU"
  bottom: "conv_1_batchnorm"
  top: "conv_1_batchnorm"
}
layer {
  name: "conv_2_dw_conv2d"
  type: "Convolution"
  bottom: "conv_1_batchnorm"
  top: "conv_2_dw_conv2d"
  convolution_param {
    num_output: 64
    bias_term: false
    group: 64
    stride: 1
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "conv_2_dw_batchnorm"
  type: "BatchNorm"
  bottom: "conv_2_dw_conv2d"
  top: "conv_2_dw_batchnorm"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000475
  }
}
layer {
  name: "conv_2_dw_batchnorm_scale"
  type: "Scale"
  bottom: "conv_2_dw_batchnorm"
  top: "conv_2_dw_batchnorm"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv_2_dw_relu"
  type: "PReLU"
  bottom: "conv_2_dw_batchnorm"
  top: "conv_2_dw_batchnorm"
}
layer {
  name: "dconv_23_conv_sep_conv2d"
  type: "Convolution"
  bottom: "conv_2_dw_batchnorm"
  top: "dconv_23_conv_sep_conv2d"
  convolution_param {
    num_output: 128
    bias_term: false
    group: 1
    stride: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "dconv_23_conv_sep_batchnorm"
  type: "BatchNorm"
  bottom: "dconv_23_conv_sep_conv2d"
  top: "dconv_23_conv_sep_batchnorm"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000475
  }
}
layer {
  name: "dconv_23_conv_sep_batchnorm_scale"
  type: "Scale"
  bottom: "dconv_23_conv_sep_batchnorm"
  top: "dconv_23_conv_sep_batchnorm"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dconv_23_conv_sep_relu"
  type: "PReLU"
  bottom: "dconv_23_conv_sep_batchnorm"
  top: "dconv_23_conv_sep_batchnorm"
}
layer {
  name: "dconv_23_conv_dw_conv2d"
  type: "Convolution"
  bottom: "dconv_23_conv_sep_batchnorm"
  top: "dconv_23_conv_dw_conv2d"
  convolution_param {
    num_output: 128
    bias_term: false
    group: 128
    stride: 2
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "dconv_23_conv_dw_batchnorm"
  type: "BatchNorm"
  bottom: "dconv_23_conv_dw_conv2d"
  top: "dconv_23_conv_dw_batchnorm"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000475
  }
}
layer {
  name: "dconv_23_conv_dw_batchnorm_scale"
  type: "Scale"
  bottom: "dconv_23_conv_dw_batchnorm"
  top: "dconv_23_conv_dw_batchnorm"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dconv_23_conv_dw_relu"
  type: "PReLU"
  bottom: "dconv_23_conv_dw_batchnorm"
  top: "dconv_23_conv_dw_batchnorm"
}
layer {
  name: "dconv_23_conv_proj_conv2d"
  type: "Convolution"
  bottom: "dconv_23_conv_dw_batchnorm"
  top: "dconv_23_conv_proj_conv2d"
  convolution_param {
    num_output: 64
    bias_term: false
    group: 1
    stride: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "dconv_23_conv_proj_batchnorm"
  type: "BatchNorm"
  bottom: "dconv_23_conv_proj_conv2d"
  top: "dconv_23_conv_proj_batchnorm"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000475
  }
}
layer {
  name: "dconv_23_conv_proj_batchnorm_scale"
  type: "Scale"
  bottom: "dconv_23_conv_proj_batchnorm"
  top: "dconv_23_conv_proj_batchnorm"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res_3_block0_conv_sep_conv2d"
  type: "Convolution"
  bottom: "dconv_23_conv_proj_batchnorm"
  top: "res_3_block0_conv_sep_conv2d"
  convolution_param {
    num_output: 128
    bias_term: false
    group: 1
    stride: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "res_3_block0_conv_sep_batchnorm"
  type: "BatchNorm"
  bottom: "res_3_block0_conv_sep_conv2d"
  top: "res_3_block0_conv_sep_batchnorm"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000475
  }
}
layer {
  name: "res_3_block0_conv_sep_batchnorm_scale"
  type: "Scale"
  bottom: "res_3_block0_conv_sep_batchnorm"
  top: "res_3_block0_conv_sep_batchnorm"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res_3_block0_conv_sep_relu"
  type: "PReLU"
  bottom: "res_3_block0_conv_sep_batchnorm"
  top: "res_3_block0_conv_sep_batchnorm"
}
layer {
  name: "res_3_block0_conv_dw_conv2d"
  type: "Convolution"
  bottom: "res_3_block0_conv_sep_batchnorm"
  top: "res_3_block0_conv_dw_conv2d"
  convolution_param {
    num_output: 128
    bias_term: false
    group: 128
    stride: 1
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "res_3_block0_conv_dw_batchnorm"
  type: "BatchNorm"
  bottom: "res_3_block0_conv_dw_conv2d"
  top: "res_3_block0_conv_dw_batchnorm"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000475
  }
}
layer {
  name: "res_3_block0_conv_dw_batchnorm_scale"
  type: "Scale"
  bottom: "res_3_block0_conv_dw_batchnorm"
  top: "res_3_block0_conv_dw_batchnorm"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res_3_block0_conv_dw_relu"
  type: "PReLU"
  bottom: "res_3_block0_conv_dw_batchnorm"
  top: "res_3_block0_conv_dw_batchnorm"
}
layer {
  name: "res_3_block0_conv_proj_conv2d"
  type: "Convolution"
  bottom: "res_3_block0_conv_dw_batchnorm"
  top: "res_3_block0_conv_proj_conv2d"
  convolution_param {
    num_output: 64
    bias_term: false
    group: 1
    stride: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "res_3_block0_conv_proj_batchnorm"
  type: "BatchNorm"
  bottom: "res_3_block0_conv_proj_conv2d"
  top: "res_3_block0_conv_proj_batchnorm"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000475
  }
}
layer {
  name: "res_3_block0_conv_proj_batchnorm_scale"
  type: "Scale"
  bottom: "res_3_block0_conv_proj_batchnorm"
  top: "res_3_block0_conv_proj_batchnorm"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "plus0"
  type: "Eltwise"
  bottom: "res_3_block0_conv_proj_batchnorm"
  bottom: "dconv_23_conv_proj_batchnorm"
  top: "plus0"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_block1_conv_sep_conv2d"
  type: "Convolution"
  bottom: "plus0"
  top: "res_3_block1_conv_sep_conv2d"
  convolution_param {
    num_output: 128
    bias_term: false
    group: 1
    stride: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "res_3_block1_conv_sep_batchnorm"
  type: "BatchNorm"
  bottom: "res_3_block1_conv_sep_conv2d"
  top: "res_3_block1_conv_sep_batchnorm"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000475
  }
}
layer {
  name: "res_3_block1_conv_sep_batchnorm_scale"
  type: "Scale"
  bottom: "res_3_block1_conv_sep_batchnorm"
  top: "res_3_block1_conv_sep_batchnorm"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res_3_block1_conv_sep_relu"
  type: "PReLU"
  bottom: "res_3_block1_conv_sep_batchnorm"
  top: "res_3_block1_conv_sep_batchnorm"
}
layer {
  name: "res_3_block1_conv_dw_conv2d"
  type: "Convolution"
  bottom: "res_3_block1_conv_sep_batchnorm"
  top: "res_3_block1_conv_dw_conv2d"
  convolution_param {
    num_output: 128
    bias_term: false
    group: 128
    stride: 1
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "res_3_block1_conv_dw_batchnorm"
  type: "BatchNorm"
  bottom: "res_3_block1_conv_dw_conv2d"
  top: "res_3_block1_conv_dw_batchnorm"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000475
  }
}
layer {
  name: "res_3_block1_conv_dw_batchnorm_scale"
  type: "Scale"
  bottom: "res_3_block1_conv_dw_batchnorm"
  top: "res_3_block1_conv_dw_batchnorm"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res_3_block1_conv_dw_relu"
  type: "PReLU"
  bottom: "res_3_block1_conv_dw_batchnorm"
  top: "res_3_block1_conv_dw_batchnorm"
}
layer {
  name: "res_3_block1_conv_proj_conv2d"
  type: "Convolution"
  bottom: "res_3_block1_conv_dw_batchnorm"
  top: "res_3_block1_conv_proj_conv2d"
  convolution_param {
    num_output: 64
    bias_term: false
    group: 1
    stride: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "res_3_block1_conv_proj_batchnorm"
  type: "BatchNorm"
  bottom: "res_3_block1_conv_proj_conv2d"
  top: "res_3_block1_conv_proj_batchnorm"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000475
  }
}
layer {
  name: "res_3_block1_conv_proj_batchnorm_scale"
  type: "Scale"
  bottom: "res_3_block1_conv_proj_batchnorm"
  top: "res_3_block1_conv_proj_batchnorm"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "plus1"
  type: "Eltwise"
  bottom: "res_3_block1_conv_proj_batchnorm"
  bottom: "plus0"
  top: "plus1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_block2_conv_sep_conv2d"
  type: "Convolution"
  bottom: "plus1"
  top: "res_3_block2_conv_sep_conv2d"
  convolution_param {
    num_output: 128
    bias_term: false
    group: 1
    stride: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "res_3_block2_conv_sep_batchnorm"
  type: "BatchNorm"
  bottom: "res_3_block2_conv_sep_conv2d"
  top: "res_3_block2_conv_sep_batchnorm"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000475
  }
}
layer {
  name: "res_3_block2_conv_sep_batchnorm_scale"
  type: "Scale"
  bottom: "res_3_block2_conv_sep_batchnorm"
  top: "res_3_block2_conv_sep_batchnorm"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res_3_block2_conv_sep_relu"
  type: "PReLU"
  bottom: "res_3_block2_conv_sep_batchnorm"
  top: "res_3_block2_conv_sep_batchnorm"
}
layer {
  name: "res_3_block2_conv_dw_conv2d"
  type: "Convolution"
  bottom: "res_3_block2_conv_sep_batchnorm"
  top: "res_3_block2_conv_dw_conv2d"
  convolution_param {
    num_output: 128
    bias_term: false
    group: 128
    stride: 1
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "res_3_block2_conv_dw_batchnorm"
  type: "BatchNorm"
  bottom: "res_3_block2_conv_dw_conv2d"
  top: "res_3_block2_conv_dw_batchnorm"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000475
  }
}
layer {
  name: "res_3_block2_conv_dw_batchnorm_scale"
  type: "Scale"
  bottom: "res_3_block2_conv_dw_batchnorm"
  top: "res_3_block2_conv_dw_batchnorm"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res_3_block2_conv_dw_relu"
  type: "PReLU"
  bottom: "res_3_block2_conv_dw_batchnorm"
  top: "res_3_block2_conv_dw_batchnorm"
}
layer {
  name: "res_3_block2_conv_proj_conv2d"
  type: "Convolution"
  bottom: "res_3_block2_conv_dw_batchnorm"
  top: "res_3_block2_conv_proj_conv2d"
  convolution_param {
    num_output: 64
    bias_term: false
    group: 1
    stride: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "res_3_block2_conv_proj_batchnorm"
  type: "BatchNorm"
  bottom: "res_3_block2_conv_proj_conv2d"
  top: "res_3_block2_conv_proj_batchnorm"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000475
  }
}
layer {
  name: "res_3_block2_conv_proj_batchnorm_scale"
  type: "Scale"
  bottom: "res_3_block2_conv_proj_batchnorm"
  top: "res_3_block2_conv_proj_batchnorm"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "plus2"
  type: "Eltwise"
  bottom: "res_3_block2_conv_proj_batchnorm"
  bottom: "plus1"
  top: "plus2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_block3_conv_sep_conv2d"
  type: "Convolution"
  bottom: "plus2"
  top: "res_3_block3_conv_sep_conv2d"
  convolution_param {
    num_output: 128
    bias_term: false
    group: 1
    stride: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "res_3_block3_conv_sep_batchnorm"
  type: "BatchNorm"
  bottom: "res_3_block3_conv_sep_conv2d"
  top: "res_3_block3_conv_sep_batchnorm"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000475
  }
}
layer {
  name: "res_3_block3_conv_sep_batchnorm_scale"
  type: "Scale"
  bottom: "res_3_block3_conv_sep_batchnorm"
  top: "res_3_block3_conv_sep_batchnorm"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res_3_block3_conv_sep_relu"
  type: "PReLU"
  bottom: "res_3_block3_conv_sep_batchnorm"
  top: "res_3_block3_conv_sep_batchnorm"
}
layer {
  name: "res_3_block3_conv_dw_conv2d"
  type: "Convolution"
  bottom: "res_3_block3_conv_sep_batchnorm"
  top: "res_3_block3_conv_dw_conv2d"
  convolution_param {
    num_output: 128
    bias_term: false
    group: 128
    stride: 1
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "res_3_block3_conv_dw_batchnorm"
  type: "BatchNorm"
  bottom: "res_3_block3_conv_dw_conv2d"
  top: "res_3_block3_conv_dw_batchnorm"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000475
  }
}
layer {
  name: "res_3_block3_conv_dw_batchnorm_scale"
  type: "Scale"
  bottom: "res_3_block3_conv_dw_batchnorm"
  top: "res_3_block3_conv_dw_batchnorm"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res_3_block3_conv_dw_relu"
  type: "PReLU"
  bottom: "res_3_block3_conv_dw_batchnorm"
  top: "res_3_block3_conv_dw_batchnorm"
}
layer {
  name: "res_3_block3_conv_proj_conv2d"
  type: "Convolution"
  bottom: "res_3_block3_conv_dw_batchnorm"
  top: "res_3_block3_conv_proj_conv2d"
  convolution_param {
    num_output: 64
    bias_term: false
    group: 1
    stride: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "res_3_block3_conv_proj_batchnorm"
  type: "BatchNorm"
  bottom: "res_3_block3_conv_proj_conv2d"
  top: "res_3_block3_conv_proj_batchnorm"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000475
  }
}
layer {
  name: "res_3_block3_conv_proj_batchnorm_scale"
  type: "Scale"
  bottom: "res_3_block3_conv_proj_batchnorm"
  top: "res_3_block3_conv_proj_batchnorm"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "plus3"
  type: "Eltwise"
  bottom: "res_3_block3_conv_proj_batchnorm"
  bottom: "plus2"
  top: "plus3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dconv_34_conv_sep_conv2d"
  type: "Convolution"
  bottom: "plus3"
  top: "dconv_34_conv_sep_conv2d"
  convolution_param {
    num_output: 256
    bias_term: false
    group: 1
    stride: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "dconv_34_conv_sep_batchnorm"
  type: "BatchNorm"
  bottom: "dconv_34_conv_sep_conv2d"
  top: "dconv_34_conv_sep_batchnorm"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000475
  }
}
layer {
  name: "dconv_34_conv_sep_batchnorm_scale"
  type: "Scale"
  bottom: "dconv_34_conv_sep_batchnorm"
  top: "dconv_34_conv_sep_batchnorm"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dconv_34_conv_sep_relu"
  type: "PReLU"
  bottom: "dconv_34_conv_sep_batchnorm"
  top: "dconv_34_conv_sep_batchnorm"
}
layer {
  name: "dconv_34_conv_dw_conv2d"
  type: "Convolution"
  bottom: "dconv_34_conv_sep_batchnorm"
  top: "dconv_34_conv_dw_conv2d"
  convolution_param {
    num_output: 256
    bias_term: false
    group: 256
    stride: 2
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "dconv_34_conv_dw_batchnorm"
  type: "BatchNorm"
  bottom: "dconv_34_conv_dw_conv2d"
  top: "dconv_34_conv_dw_batchnorm"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000475
  }
}
layer {
  name: "dconv_34_conv_dw_batchnorm_scale"
  type: "Scale"
  bottom: "dconv_34_conv_dw_batchnorm"
  top: "dconv_34_conv_dw_batchnorm"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dconv_34_conv_dw_relu"
  type: "PReLU"
  bottom: "dconv_34_conv_dw_batchnorm"
  top: "dconv_34_conv_dw_batchnorm"
}
layer {
  name: "dconv_34_conv_proj_conv2d"
  type: "Convolution"
  bottom: "dconv_34_conv_dw_batchnorm"
  top: "dconv_34_conv_proj_conv2d"
  convolution_param {
    num_output: 128
    bias_term: false
    group: 1
    stride: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "dconv_34_conv_proj_batchnorm"
  type: "BatchNorm"
  bottom: "dconv_34_conv_proj_conv2d"
  top: "dconv_34_conv_proj_batchnorm"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000475
  }
}
layer {
  name: "dconv_34_conv_proj_batchnorm_scale"
  type: "Scale"
  bottom: "dconv_34_conv_proj_batchnorm"
  top: "dconv_34_conv_proj_batchnorm"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res_4_block0_conv_sep_conv2d"
  type: "Convolution"
  bottom: "dconv_34_conv_proj_batchnorm"
  top: "res_4_block0_conv_sep_conv2d"
  convolution_param {
    num_output: 256
    bias_term: false
    group: 1
    stride: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "res_4_block0_conv_sep_batchnorm"
  type: "BatchNorm"
  bottom: "res_4_block0_conv_sep_conv2d"
  top: "res_4_block0_conv_sep_batchnorm"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000475
  }
}
layer {
  name: "res_4_block0_conv_sep_batchnorm_scale"
  type: "Scale"
  bottom: "res_4_block0_conv_sep_batchnorm"
  top: "res_4_block0_conv_sep_batchnorm"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res_4_block0_conv_sep_relu"
  type: "PReLU"
  bottom: "res_4_block0_conv_sep_batchnorm"
  top: "res_4_block0_conv_sep_batchnorm"
}
layer {
  name: "res_4_block0_conv_dw_conv2d"
  type: "Convolution"
  bottom: "res_4_block0_conv_sep_batchnorm"
  top: "res_4_block0_conv_dw_conv2d"
  convolution_param {
    num_output: 256
    bias_term: false
    group: 256
    stride: 1
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "res_4_block0_conv_dw_batchnorm"
  type: "BatchNorm"
  bottom: "res_4_block0_conv_dw_conv2d"
  top: "res_4_block0_conv_dw_batchnorm"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000475
  }
}
layer {
  name: "res_4_block0_conv_dw_batchnorm_scale"
  type: "Scale"
  bottom: "res_4_block0_conv_dw_batchnorm"
  top: "res_4_block0_conv_dw_batchnorm"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res_4_block0_conv_dw_relu"
  type: "PReLU"
  bottom: "res_4_block0_conv_dw_batchnorm"
  top: "res_4_block0_conv_dw_batchnorm"
}
layer {
  name: "res_4_block0_conv_proj_conv2d"
  type: "Convolution"
  bottom: "res_4_block0_conv_dw_batchnorm"
  top: "res_4_block0_conv_proj_conv2d"
  convolution_param {
    num_output: 128
    bias_term: false
    group: 1
    stride: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "res_4_block0_conv_proj_batchnorm"
  type: "BatchNorm"
  bottom: "res_4_block0_conv_proj_conv2d"
  top: "res_4_block0_conv_proj_batchnorm"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000475
  }
}
layer {
  name: "res_4_block0_conv_proj_batchnorm_scale"
  type: "Scale"
  bottom: "res_4_block0_conv_proj_batchnorm"
  top: "res_4_block0_conv_proj_batchnorm"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "plus4"
  type: "Eltwise"
  bottom: "res_4_block0_conv_proj_batchnorm"
  bottom: "dconv_34_conv_proj_batchnorm"
  top: "plus4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_4_block1_conv_sep_conv2d"
  type: "Convolution"
  bottom: "plus4"
  top: "res_4_block1_conv_sep_conv2d"
  convolution_param {
    num_output: 256
    bias_term: false
    group: 1
    stride: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "res_4_block1_conv_sep_batchnorm"
  type: "BatchNorm"
  bottom: "res_4_block1_conv_sep_conv2d"
  top: "res_4_block1_conv_sep_batchnorm"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000475
  }
}
layer {
  name: "res_4_block1_conv_sep_batchnorm_scale"
  type: "Scale"
  bottom: "res_4_block1_conv_sep_batchnorm"
  top: "res_4_block1_conv_sep_batchnorm"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res_4_block1_conv_sep_relu"
  type: "PReLU"
  bottom: "res_4_block1_conv_sep_batchnorm"
  top: "res_4_block1_conv_sep_batchnorm"
}
layer {
  name: "res_4_block1_conv_dw_conv2d"
  type: "Convolution"
  bottom: "res_4_block1_conv_sep_batchnorm"
  top: "res_4_block1_conv_dw_conv2d"
  convolution_param {
    num_output: 256
    bias_term: false
    group: 256
    stride: 1
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "res_4_block1_conv_dw_batchnorm"
  type: "BatchNorm"
  bottom: "res_4_block1_conv_dw_conv2d"
  top: "res_4_block1_conv_dw_batchnorm"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000475
  }
}
layer {
  name: "res_4_block1_conv_dw_batchnorm_scale"
  type: "Scale"
  bottom: "res_4_block1_conv_dw_batchnorm"
  top: "res_4_block1_conv_dw_batchnorm"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res_4_block1_conv_dw_relu"
  type: "PReLU"
  bottom: "res_4_block1_conv_dw_batchnorm"
  top: "res_4_block1_conv_dw_batchnorm"
}
layer {
  name: "res_4_block1_conv_proj_conv2d"
  type: "Convolution"
  bottom: "res_4_block1_conv_dw_batchnorm"
  top: "res_4_block1_conv_proj_conv2d"
  convolution_param {
    num_output: 128
    bias_term: false
    group: 1
    stride: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "res_4_block1_conv_proj_batchnorm"
  type: "BatchNorm"
  bottom: "res_4_block1_conv_proj_conv2d"
  top: "res_4_block1_conv_proj_batchnorm"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000475
  }
}
layer {
  name: "res_4_block1_conv_proj_batchnorm_scale"
  type: "Scale"
  bottom: "res_4_block1_conv_proj_batchnorm"
  top: "res_4_block1_conv_proj_batchnorm"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "plus5"
  type: "Eltwise"
  bottom: "res_4_block1_conv_proj_batchnorm"
  bottom: "plus4"
  top: "plus5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_4_block2_conv_sep_conv2d"
  type: "Convolution"
  bottom: "plus5"
  top: "res_4_block2_conv_sep_conv2d"
  convolution_param {
    num_output: 256
    bias_term: false
    group: 1
    stride: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "res_4_block2_conv_sep_batchnorm"
  type: "BatchNorm"
  bottom: "res_4_block2_conv_sep_conv2d"
  top: "res_4_block2_conv_sep_batchnorm"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000475
  }
}
layer {
  name: "res_4_block2_conv_sep_batchnorm_scale"
  type: "Scale"
  bottom: "res_4_block2_conv_sep_batchnorm"
  top: "res_4_block2_conv_sep_batchnorm"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res_4_block2_conv_sep_relu"
  type: "PReLU"
  bottom: "res_4_block2_conv_sep_batchnorm"
  top: "res_4_block2_conv_sep_batchnorm"
}
layer {
  name: "res_4_block2_conv_dw_conv2d"
  type: "Convolution"
  bottom: "res_4_block2_conv_sep_batchnorm"
  top: "res_4_block2_conv_dw_conv2d"
  convolution_param {
    num_output: 256
    bias_term: false
    group: 256
    stride: 1
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "res_4_block2_conv_dw_batchnorm"
  type: "BatchNorm"
  bottom: "res_4_block2_conv_dw_conv2d"
  top: "res_4_block2_conv_dw_batchnorm"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000475
  }
}
layer {
  name: "res_4_block2_conv_dw_batchnorm_scale"
  type: "Scale"
  bottom: "res_4_block2_conv_dw_batchnorm"
  top: "res_4_block2_conv_dw_batchnorm"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res_4_block2_conv_dw_relu"
  type: "PReLU"
  bottom: "res_4_block2_conv_dw_batchnorm"
  top: "res_4_block2_conv_dw_batchnorm"
}
layer {
  name: "res_4_block2_conv_proj_conv2d"
  type: "Convolution"
  bottom: "res_4_block2_conv_dw_batchnorm"
  top: "res_4_block2_conv_proj_conv2d"
  convolution_param {
    num_output: 128
    bias_term: false
    group: 1
    stride: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "res_4_block2_conv_proj_batchnorm"
  type: "BatchNorm"
  bottom: "res_4_block2_conv_proj_conv2d"
  top: "res_4_block2_conv_proj_batchnorm"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000475
  }
}
layer {
  name: "res_4_block2_conv_proj_batchnorm_scale"
  type: "Scale"
  bottom: "res_4_block2_conv_proj_batchnorm"
  top: "res_4_block2_conv_proj_batchnorm"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "plus6"
  type: "Eltwise"
  bottom: "res_4_block2_conv_proj_batchnorm"
  bottom: "plus5"
  top: "plus6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_4_block3_conv_sep_conv2d"
  type: "Convolution"
  bottom: "plus6"
  top: "res_4_block3_conv_sep_conv2d"
  convolution_param {
    num_output: 256
    bias_term: false
    group: 1
    stride: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "res_4_block3_conv_sep_batchnorm"
  type: "BatchNorm"
  bottom: "res_4_block3_conv_sep_conv2d"
  top: "res_4_block3_conv_sep_batchnorm"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000475
  }
}
layer {
  name: "res_4_block3_conv_sep_batchnorm_scale"
  type: "Scale"
  bottom: "res_4_block3_conv_sep_batchnorm"
  top: "res_4_block3_conv_sep_batchnorm"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res_4_block3_conv_sep_relu"
  type: "PReLU"
  bottom: "res_4_block3_conv_sep_batchnorm"
  top: "res_4_block3_conv_sep_batchnorm"
}
layer {
  name: "res_4_block3_conv_dw_conv2d"
  type: "Convolution"
  bottom: "res_4_block3_conv_sep_batchnorm"
  top: "res_4_block3_conv_dw_conv2d"
  convolution_param {
    num_output: 256
    bias_term: false
    group: 256
    stride: 1
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "res_4_block3_conv_dw_batchnorm"
  type: "BatchNorm"
  bottom: "res_4_block3_conv_dw_conv2d"
  top: "res_4_block3_conv_dw_batchnorm"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000475
  }
}
layer {
  name: "res_4_block3_conv_dw_batchnorm_scale"
  type: "Scale"
  bottom: "res_4_block3_conv_dw_batchnorm"
  top: "res_4_block3_conv_dw_batchnorm"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res_4_block3_conv_dw_relu"
  type: "PReLU"
  bottom: "res_4_block3_conv_dw_batchnorm"
  top: "res_4_block3_conv_dw_batchnorm"
}
layer {
  name: "res_4_block3_conv_proj_conv2d"
  type: "Convolution"
  bottom: "res_4_block3_conv_dw_batchnorm"
  top: "res_4_block3_conv_proj_conv2d"
  convolution_param {
    num_output: 128
    bias_term: false
    group: 1
    stride: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "res_4_block3_conv_proj_batchnorm"
  type: "BatchNorm"
  bottom: "res_4_block3_conv_proj_conv2d"
  top: "res_4_block3_conv_proj_batchnorm"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000475
  }
}
layer {
  name: "res_4_block3_conv_proj_batchnorm_scale"
  type: "Scale"
  bottom: "res_4_block3_conv_proj_batchnorm"
  top: "res_4_block3_conv_proj_batchnorm"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "plus7"
  type: "Eltwise"
  bottom: "res_4_block3_conv_proj_batchnorm"
  bottom: "plus6"
  top: "plus7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_4_block4_conv_sep_conv2d"
  type: "Convolution"
  bottom: "plus7"
  top: "res_4_block4_conv_sep_conv2d"
  convolution_param {
    num_output: 256
    bias_term: false
    group: 1
    stride: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "res_4_block4_conv_sep_batchnorm"
  type: "BatchNorm"
  bottom: "res_4_block4_conv_sep_conv2d"
  top: "res_4_block4_conv_sep_batchnorm"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000475
  }
}
layer {
  name: "res_4_block4_conv_sep_batchnorm_scale"
  type: "Scale"
  bottom: "res_4_block4_conv_sep_batchnorm"
  top: "res_4_block4_conv_sep_batchnorm"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res_4_block4_conv_sep_relu"
  type: "PReLU"
  bottom: "res_4_block4_conv_sep_batchnorm"
  top: "res_4_block4_conv_sep_batchnorm"
}
layer {
  name: "res_4_block4_conv_dw_conv2d"
  type: "Convolution"
  bottom: "res_4_block4_conv_sep_batchnorm"
  top: "res_4_block4_conv_dw_conv2d"
  convolution_param {
    num_output: 256
    bias_term: false
    group: 256
    stride: 1
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "res_4_block4_conv_dw_batchnorm"
  type: "BatchNorm"
  bottom: "res_4_block4_conv_dw_conv2d"
  top: "res_4_block4_conv_dw_batchnorm"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000475
  }
}
layer {
  name: "res_4_block4_conv_dw_batchnorm_scale"
  type: "Scale"
  bottom: "res_4_block4_conv_dw_batchnorm"
  top: "res_4_block4_conv_dw_batchnorm"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res_4_block4_conv_dw_relu"
  type: "PReLU"
  bottom: "res_4_block4_conv_dw_batchnorm"
  top: "res_4_block4_conv_dw_batchnorm"
}
layer {
  name: "res_4_block4_conv_proj_conv2d"
  type: "Convolution"
  bottom: "res_4_block4_conv_dw_batchnorm"
  top: "res_4_block4_conv_proj_conv2d"
  convolution_param {
    num_output: 128
    bias_term: false
    group: 1
    stride: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "res_4_block4_conv_proj_batchnorm"
  type: "BatchNorm"
  bottom: "res_4_block4_conv_proj_conv2d"
  top: "res_4_block4_conv_proj_batchnorm"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000475
  }
}
layer {
  name: "res_4_block4_conv_proj_batchnorm_scale"
  type: "Scale"
  bottom: "res_4_block4_conv_proj_batchnorm"
  top: "res_4_block4_conv_proj_batchnorm"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "plus8"
  type: "Eltwise"
  bottom: "res_4_block4_conv_proj_batchnorm"
  bottom: "plus7"
  top: "plus8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_4_block5_conv_sep_conv2d"
  type: "Convolution"
  bottom: "plus8"
  top: "res_4_block5_conv_sep_conv2d"
  convolution_param {
    num_output: 256
    bias_term: false
    group: 1
    stride: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "res_4_block5_conv_sep_batchnorm"
  type: "BatchNorm"
  bottom: "res_4_block5_conv_sep_conv2d"
  top: "res_4_block5_conv_sep_batchnorm"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000475
  }
}
layer {
  name: "res_4_block5_conv_sep_batchnorm_scale"
  type: "Scale"
  bottom: "res_4_block5_conv_sep_batchnorm"
  top: "res_4_block5_conv_sep_batchnorm"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res_4_block5_conv_sep_relu"
  type: "PReLU"
  bottom: "res_4_block5_conv_sep_batchnorm"
  top: "res_4_block5_conv_sep_batchnorm"
}
layer {
  name: "res_4_block5_conv_dw_conv2d"
  type: "Convolution"
  bottom: "res_4_block5_conv_sep_batchnorm"
  top: "res_4_block5_conv_dw_conv2d"
  convolution_param {
    num_output: 256
    bias_term: false
    group: 256
    stride: 1
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "res_4_block5_conv_dw_batchnorm"
  type: "BatchNorm"
  bottom: "res_4_block5_conv_dw_conv2d"
  top: "res_4_block5_conv_dw_batchnorm"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000475
  }
}
layer {
  name: "res_4_block5_conv_dw_batchnorm_scale"
  type: "Scale"
  bottom: "res_4_block5_conv_dw_batchnorm"
  top: "res_4_block5_conv_dw_batchnorm"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res_4_block5_conv_dw_relu"
  type: "PReLU"
  bottom: "res_4_block5_conv_dw_batchnorm"
  top: "res_4_block5_conv_dw_batchnorm"
}
layer {
  name: "res_4_block5_conv_proj_conv2d"
  type: "Convolution"
  bottom: "res_4_block5_conv_dw_batchnorm"
  top: "res_4_block5_conv_proj_conv2d"
  convolution_param {
    num_output: 128
    bias_term: false
    group: 1
    stride: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "res_4_block5_conv_proj_batchnorm"
  type: "BatchNorm"
  bottom: "res_4_block5_conv_proj_conv2d"
  top: "res_4_block5_conv_proj_batchnorm"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000475
  }
}
layer {
  name: "res_4_block5_conv_proj_batchnorm_scale"
  type: "Scale"
  bottom: "res_4_block5_conv_proj_batchnorm"
  top: "res_4_block5_conv_proj_batchnorm"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "plus9"
  type: "Eltwise"
  bottom: "res_4_block5_conv_proj_batchnorm"
  bottom: "plus8"
  top: "plus9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dconv_45_conv_sep_conv2d"
  type: "Convolution"
  bottom: "plus9"
  top: "dconv_45_conv_sep_conv2d"
  convolution_param {
    num_output: 512
    bias_term: false
    group: 1
    stride: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "dconv_45_conv_sep_batchnorm"
  type: "BatchNorm"
  bottom: "dconv_45_conv_sep_conv2d"
  top: "dconv_45_conv_sep_batchnorm"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000475
  }
}
layer {
  name: "dconv_45_conv_sep_batchnorm_scale"
  type: "Scale"
  bottom: "dconv_45_conv_sep_batchnorm"
  top: "dconv_45_conv_sep_batchnorm"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dconv_45_conv_sep_relu"
  type: "PReLU"
  bottom: "dconv_45_conv_sep_batchnorm"
  top: "dconv_45_conv_sep_batchnorm"
}
layer {
  name: "dconv_45_conv_dw_conv2d"
  type: "Convolution"
  bottom: "dconv_45_conv_sep_batchnorm"
  top: "dconv_45_conv_dw_conv2d"
  convolution_param {
    num_output: 512
    bias_term: false
    group: 512
    stride: 2
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "dconv_45_conv_dw_batchnorm"
  type: "BatchNorm"
  bottom: "dconv_45_conv_dw_conv2d"
  top: "dconv_45_conv_dw_batchnorm"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000475
  }
}
layer {
  name: "dconv_45_conv_dw_batchnorm_scale"
  type: "Scale"
  bottom: "dconv_45_conv_dw_batchnorm"
  top: "dconv_45_conv_dw_batchnorm"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dconv_45_conv_dw_relu"
  type: "PReLU"
  bottom: "dconv_45_conv_dw_batchnorm"
  top: "dconv_45_conv_dw_batchnorm"
}
layer {
  name: "dconv_45_conv_proj_conv2d"
  type: "Convolution"
  bottom: "dconv_45_conv_dw_batchnorm"
  top: "dconv_45_conv_proj_conv2d"
  convolution_param {
    num_output: 128
    bias_term: false
    group: 1
    stride: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "dconv_45_conv_proj_batchnorm"
  type: "BatchNorm"
  bottom: "dconv_45_conv_proj_conv2d"
  top: "dconv_45_conv_proj_batchnorm"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000475
  }
}
layer {
  name: "dconv_45_conv_proj_batchnorm_scale"
  type: "Scale"
  bottom: "dconv_45_conv_proj_batchnorm"
  top: "dconv_45_conv_proj_batchnorm"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res_5_block0_conv_sep_conv2d"
  type: "Convolution"
  bottom: "dconv_45_conv_proj_batchnorm"
  top: "res_5_block0_conv_sep_conv2d"
  convolution_param {
    num_output: 256
    bias_term: false
    group: 1
    stride: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "res_5_block0_conv_sep_batchnorm"
  type: "BatchNorm"
  bottom: "res_5_block0_conv_sep_conv2d"
  top: "res_5_block0_conv_sep_batchnorm"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000475
  }
}
layer {
  name: "res_5_block0_conv_sep_batchnorm_scale"
  type: "Scale"
  bottom: "res_5_block0_conv_sep_batchnorm"
  top: "res_5_block0_conv_sep_batchnorm"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res_5_block0_conv_sep_relu"
  type: "PReLU"
  bottom: "res_5_block0_conv_sep_batchnorm"
  top: "res_5_block0_conv_sep_batchnorm"
}
layer {
  name: "res_5_block0_conv_dw_conv2d"
  type: "Convolution"
  bottom: "res_5_block0_conv_sep_batchnorm"
  top: "res_5_block0_conv_dw_conv2d"
  convolution_param {
    num_output: 256
    bias_term: false
    group: 256
    stride: 1
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "res_5_block0_conv_dw_batchnorm"
  type: "BatchNorm"
  bottom: "res_5_block0_conv_dw_conv2d"
  top: "res_5_block0_conv_dw_batchnorm"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000475
  }
}
layer {
  name: "res_5_block0_conv_dw_batchnorm_scale"
  type: "Scale"
  bottom: "res_5_block0_conv_dw_batchnorm"
  top: "res_5_block0_conv_dw_batchnorm"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res_5_block0_conv_dw_relu"
  type: "PReLU"
  bottom: "res_5_block0_conv_dw_batchnorm"
  top: "res_5_block0_conv_dw_batchnorm"
}
layer {
  name: "res_5_block0_conv_proj_conv2d"
  type: "Convolution"
  bottom: "res_5_block0_conv_dw_batchnorm"
  top: "res_5_block0_conv_proj_conv2d"
  convolution_param {
    num_output: 128
    bias_term: false
    group: 1
    stride: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "res_5_block0_conv_proj_batchnorm"
  type: "BatchNorm"
  bottom: "res_5_block0_conv_proj_conv2d"
  top: "res_5_block0_conv_proj_batchnorm"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000475
  }
}
layer {
  name: "res_5_block0_conv_proj_batchnorm_scale"
  type: "Scale"
  bottom: "res_5_block0_conv_proj_batchnorm"
  top: "res_5_block0_conv_proj_batchnorm"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "plus10"
  type: "Eltwise"
  bottom: "res_5_block0_conv_proj_batchnorm"
  bottom: "dconv_45_conv_proj_batchnorm"
  top: "plus10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_5_block1_conv_sep_conv2d"
  type: "Convolution"
  bottom: "plus10"
  top: "res_5_block1_conv_sep_conv2d"
  convolution_param {
    num_output: 256
    bias_term: false
    group: 1
    stride: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "res_5_block1_conv_sep_batchnorm"
  type: "BatchNorm"
  bottom: "res_5_block1_conv_sep_conv2d"
  top: "res_5_block1_conv_sep_batchnorm"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000475
  }
}
layer {
  name: "res_5_block1_conv_sep_batchnorm_scale"
  type: "Scale"
  bottom: "res_5_block1_conv_sep_batchnorm"
  top: "res_5_block1_conv_sep_batchnorm"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res_5_block1_conv_sep_relu"
  type: "PReLU"
  bottom: "res_5_block1_conv_sep_batchnorm"
  top: "res_5_block1_conv_sep_batchnorm"
}
layer {
  name: "res_5_block1_conv_dw_conv2d"
  type: "Convolution"
  bottom: "res_5_block1_conv_sep_batchnorm"
  top: "res_5_block1_conv_dw_conv2d"
  convolution_param {
    num_output: 256
    bias_term: false
    group: 256
    stride: 1
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "res_5_block1_conv_dw_batchnorm"
  type: "BatchNorm"
  bottom: "res_5_block1_conv_dw_conv2d"
  top: "res_5_block1_conv_dw_batchnorm"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000475
  }
}
layer {
  name: "res_5_block1_conv_dw_batchnorm_scale"
  type: "Scale"
  bottom: "res_5_block1_conv_dw_batchnorm"
  top: "res_5_block1_conv_dw_batchnorm"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res_5_block1_conv_dw_relu"
  type: "PReLU"
  bottom: "res_5_block1_conv_dw_batchnorm"
  top: "res_5_block1_conv_dw_batchnorm"
}
layer {
  name: "res_5_block1_conv_proj_conv2d"
  type: "Convolution"
  bottom: "res_5_block1_conv_dw_batchnorm"
  top: "res_5_block1_conv_proj_conv2d"
  convolution_param {
    num_output: 128
    bias_term: false
    group: 1
    stride: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "res_5_block1_conv_proj_batchnorm"
  type: "BatchNorm"
  bottom: "res_5_block1_conv_proj_conv2d"
  top: "res_5_block1_conv_proj_batchnorm"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000475
  }
}
layer {
  name: "res_5_block1_conv_proj_batchnorm_scale"
  type: "Scale"
  bottom: "res_5_block1_conv_proj_batchnorm"
  top: "res_5_block1_conv_proj_batchnorm"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "plus11"
  type: "Eltwise"
  bottom: "res_5_block1_conv_proj_batchnorm"
  bottom: "plus10"
  top: "plus11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv_6sep_conv2d"
  type: "Convolution"
  bottom: "plus11"
  top: "conv_6sep_conv2d"
  convolution_param {
    num_output: 512
    bias_term: false
    group: 1
    stride: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "conv_6sep_batchnorm"
  type: "BatchNorm"
  bottom: "conv_6sep_conv2d"
  top: "conv_6sep_batchnorm"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000475
  }
}
layer {
  name: "conv_6sep_batchnorm_scale"
  type: "Scale"
  bottom: "conv_6sep_batchnorm"
  top: "conv_6sep_batchnorm"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv_6sep_relu"
  type: "PReLU"
  bottom: "conv_6sep_batchnorm"
  top: "conv_6sep_batchnorm"
}
layer {
  name: "conv_6dw7_7_conv2d"
  type: "Convolution"
  bottom: "conv_6sep_batchnorm"
  top: "conv_6dw7_7_conv2d"
  convolution_param {
    num_output: 512
    bias_term: false
    group: 512
    stride: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 7
    kernel_w: 7
  }
}
layer {
  name: "conv_6dw7_7_batchnorm"
  type: "BatchNorm"
  bottom: "conv_6dw7_7_conv2d"
  top: "conv_6dw7_7_batchnorm"
  batch_norm_param {
    use_global_stats: true
    eps: 0.0010000000475
  }
}
layer {
  name: "conv_6dw7_7_batchnorm_scale"
  type: "Scale"
  bottom: "conv_6dw7_7_batchnorm"
  top: "conv_6dw7_7_batchnorm"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "pre_fc1"
  type: "InnerProduct"
  bottom: "conv_6dw7_7_batchnorm"
  top: "pre_fc1"
  inner_product_param {
    num_output: 128
    bias_term: true
  }
}
layer {
  name: "fc1"
  type: "BatchNorm"
  bottom: "pre_fc1"
  top: "fc1"
  batch_norm_param {
    use_global_stats: true
    eps: 1.99999994948e-05
  }
}
layer {
  name: "fc1_scale"
  type: "Scale"
  bottom: "fc1"
  top: "fc1"
  scale_param {
    bias_term: true
  }
}

